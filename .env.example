# ============================================
# X/Twitter API Configuration (PREFERRED)
# ============================================
# Get your API credentials from: https://developer.twitter.com/en/portal/dashboard
# Required scopes: tweet.read, users.read, offline.access
X_API_BEARER_TOKEN=your_bearer_token_here
X_API_KEY=your_api_key_here
X_API_SECRET=your_api_secret_here
X_API_ACCESS_TOKEN=your_access_token_here
X_API_ACCESS_SECRET=your_access_secret_here

# Target account to scrape (default: elonmusk)
X_TARGET_USERNAME=elonmusk

# ============================================
# Database Configuration
# ============================================
# Production: PostgreSQL
DATABASE_URL=postgresql://scraper:scraper_password@postgres:5432/x_scraper

# Development/Testing: SQLite (comment out DATABASE_URL above to use this)
# DATABASE_URL=sqlite:///./x_scraper.db

# ============================================
# Redis Configuration (for Celery)
# ============================================
REDIS_URL=redis://redis:6379/0
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/1

# ============================================
# API Server Configuration
# ============================================
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
API_RELOAD=false

# CORS Origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# ============================================
# Scraping Configuration
# ============================================
# Use API by default; fallback to scraping if API credentials missing
USE_API_FIRST=true

# Scraping rate limits (requests per second) - BE CONSERVATIVE!
SCRAPER_RATE_LIMIT=0.5
SCRAPER_MAX_RETRIES=3
SCRAPER_BACKOFF_FACTOR=2.0
SCRAPER_TIMEOUT=30

# Headless browser mode
PLAYWRIGHT_HEADLESS=true

# ============================================
# Job Scheduling (Celery Beat)
# ============================================
# Cron schedule for automatic collection (default: every 15 minutes)
COLLECTION_CRON_MINUTE=*/15
COLLECTION_CRON_HOUR=*

# Maximum posts to fetch per job (safety limit)
MAX_POSTS_PER_JOB=200

# ============================================
# Logging & Monitoring
# ============================================
LOG_LEVEL=INFO
LOG_FORMAT=json  # json or text

# Enable metrics endpoint
ENABLE_METRICS=true

# ============================================
# Security
# ============================================
# Secret key for session management (generate with: openssl rand -hex 32)
SECRET_KEY=change_this_to_a_random_secret_key_in_production

# ============================================
# Storage Configuration
# ============================================
# Media storage mode: url_only, local, s3
MEDIA_STORAGE_MODE=url_only

# If local storage:
# MEDIA_STORAGE_PATH=./media

# If S3 storage:
# AWS_ACCESS_KEY_ID=your_key
# AWS_SECRET_ACCESS_KEY=your_secret
# AWS_S3_BUCKET=your-bucket
# AWS_S3_REGION=us-east-1
